Data Ingestion Workflow and Storage

1) Raw Data Sources
    The Odds Api (primary)
    Basketball-API (secondary to the Odds API, supplemental when applicable)
    Kaggle
    NCAAr Files
    Github/open sources

2) Single source of storage truth as well as api pulls
    Azure Blob Storace "ncaamhistoricaldata" within ncaam-gbsv-model-rg
    All historical backtesting, and prediction models production ready when applicable, pull historical data needed from the single source of truth/Azure Blob Storage as to maintain data integrity, modularity, and accuracy... avoiding drift/confusion across scripts and modules/models

3) Raw Data > Standardization to a single source of true for historical backtesting/version control/maintenance
    For this phase, raw data and consolidation focuses only on seasons 2023 - 2024, 2024-2025, 2025-2026 through today() - 3 days as to avoid leakage
        Seasons must be defined and marked accordingly to avoid our scripts/backtesting from getting confused and assuming the dates have peculiar "rest" or "timing" gaps
    After raw data is pulled/imported/cached/stored as Raw Data
    Raw data is standardized BEFORE any merging/consolidation attempts
        Team Name Variants
            1) Cache/Store Team Name Variants used as Team IDs and variants in a single source of Team Variant Database for every season by source 
            2) Team name variants may change and have additions/changes from YoY seasons - but should not have significant changes, rewrite the entire single source of truth.. but only add new teams from season changes.. or identify if any new team variants are used in the data sources
            3) Every available data point must be used/optimized and not overlooked across all available data sources
            4) Historical data must be unique and standardized from the raw data, prior to merging/consolidation for fields such as 1st Half and Full Game odds/metrics/scores/etc. 
            5)If a season only has partial data from a source, it must be identified and marked accordingly in the single source of truth 
            6) For variables and metrics/data used in the historical backtesting that avoids leakage, use the data points available without disrupting the integrity of the backtesting models... but that just means a smaller set of data points for that season from that source, for that workflow. 