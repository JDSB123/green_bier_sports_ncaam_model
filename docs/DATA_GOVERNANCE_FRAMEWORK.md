# DATA GOVERNANCE FRAMEWORK
## NO Placeholders | NO Silent Fallbacks | Guard Rails | Clear QA/QC

**Last Updated:** January 12, 2026  
**Status:** Implementation Ready  
**Owner:** Data Engineering Team

---

## ğŸ¯ Executive Summary

Your question: *"How do we confirm we are implementing/incorporating into a single source of truth document with no placeholders or assumption or silent fallbacks with guard rails and clear qa/qc implementations for ALL data sources ingested from all RAW, including but not limited to the extensive NCAAR and Kaggle data sets"*

**Answer:** A three-layer governance framework:

1. **EXPLICIT DECLARATION** - Every data source formally registered with status, paths, coverage expectations
2. **GUARD RAILS** - Validation rules that BLOCK bad data (no silent fallbacks)
3. **IMMUTABLE AUDIT TRAIL** - Every validation result logged and persisted

---

## ğŸ“‹ Part 1: ALL Data Sources - Explicit Declaration

### Currently ACTIVE (Ingesting)

| Source | Data Type | Status | Guard Rails | Coverage | Audit Trail |
|--------|-----------|--------|-------------|----------|------------|
| **The Odds API** | Odds (Spreads, Totals, Moneylines) | âœ… ACTIVE | 5 rules | 81-88% | âœ“ |
| **ESPN API** | Scores (FG + H1) | âœ… ACTIVE | 4 rules | 95-100% | âœ“ |
| **Barttorvik** | Efficiency Ratings | âœ… ACTIVE | 3 rules | 80-95% | âœ“ |

### Currently INACTIVE (Available, Not Ingested)

| Source | Data Type | Status | Why Inactive | Next Steps |
|--------|-----------|--------|-------------|-----------|
| **NCAAR** | Box Scores, Play-by-Play | â¸ï¸ INACTIVE | Used for features only (build_consolidated_master.py) | Integrate through canonical pipeline |
| **Kaggle** | Tournament Scores | â¸ï¸ INACTIVE | Local CSV, tournament-only (68 games), no odds | Sync to Azure, implement merging logic |

### PLANNED (Scheduled)

| Source | Data Type | Target Date | Priority |
|--------|-----------|------------|----------|
| **Basketball-API** | Scores + Odds (secondary) | Q2 2026 | Medium |

### BLOCKED (Cannot Ingest)

| Source | Reason |
|--------|--------|
| **ESPN Box Scores** | No public API. Web scraping violates ToS. Use NCAAR instead. |

---

## ğŸ›¡ï¸ Part 2: Guard Rails - No Silent Fallbacks

Each active data source has **explicit validation rules** that BLOCK bad data:

### The Odds API - 5 Guard Rails

```python
GuardRail #1: NO HARDCODED -110 ODDS
â”œâ”€ Rule: "NEVER use hardcoded -110. ALL prices must come from source."
â”œâ”€ Validator: assert df['spread_home_price'].notnull().all()
â”œâ”€ Severity: ERROR (blocks ingestion)
â”œâ”€ Why: Hardcoded -110 assumes symmetric pricing. Real odds are asymmetric.
â””â”€ Documentation: Prevents entire classes of ROI miscalculations

GuardRail #2: SPREAD SIGN CONVENTION
â”œâ”€ Rule: "Negative = home favored, positive = away favored. CONSISTENT."
â”œâ”€ Validator: verify_spread_sign_consistency(df)
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Sign confusion flips prediction directions.
â””â”€ Example: spread=-5.5 means home favored by 5.5 (negative)

GuardRail #3: ODD PRICE RANGES
â”œâ”€ Rule: "American odds must be [-500, +500]. Outside = corruption."
â”œâ”€ Validator: assert df['spread_home_price'].between(-500, 500).all()
â”œâ”€ Severity: WARNING (logs issue, continues)
â”œâ”€ Why: Out-of-range prices indicate parsing or feed errors.
â””â”€ Action: Review and correct before using

GuardRail #4: NO DUPLICATE GAMES
â”œâ”€ Rule: "Each game appears at most once per market per day."
â”œâ”€ Validator: assert df.groupby(['game_id', 'market']).size() <= 1
â”œâ”€ Rule: "Each unique (home_team, away_team, market, game_date, game_id) appears at most once."
â”œâ”€ Validator: duplicates = df.groupby(['game_id', 'home_team', 'away_team', 'market', 'game_date']).size(); assert duplicates.max() == 1
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Duplicates cause double-counting in backtests.
â””â”€ Action: Deduplicate before ingestion

GuardRail #5: ODDS FRESHNESS BY SEASON
â”œâ”€ Rule: "Current season: <48hrs old. Historical: <10 days old."
â”œâ”€ Validator: check_odds_freshness_by_season(df)
â”œâ”€ Severity: WARNING
â”œâ”€ Why: Stale odds don't represent actual market conditions.
â””â”€ Action: Verify daily updates for current season
```

### ESPN API - 4 Guard Rails

```python
GuardRail #1: COMPLETE SCORES REQUIRED
â”œâ”€ Rule: "If home_score is not null, away_score must also not be null."
â”œâ”€ Validator: assert (df['home_score'].isnull() == df['away_score'].isnull())
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Partial scores cause backtest errors and mismatched joins.
â””â”€ Action: Skip incomplete games or wait for completion

GuardRail #2: REASONABLE SCORE RANGES
â”œâ”€ Rule: "College basketball: 0-200. Completed games: 1-200."
â”œâ”€ Validator: assert df['home_score'].between(1, 200).all()
â”œâ”€ Severity: WARNING
â”œâ”€ Why: Unreasonable scores indicate data corruption.
â””â”€ Action: Investigate and correct source data

GuardRail #3: MANDATORY TEAM RESOLUTION
â”œâ”€ Rule: "All team names must resolve to canonical names. ZERO unresolved."
â”œâ”€ Validator: assert df['home_team'].isin(CANONICAL_TEAMS).all()
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Unresolved teams fail joins with odds/ratings data.
â””â”€ Action: Add to team_aliases_db.json, re-run resolution

GuardRail #4: DATE STANDARDIZATION
â”œâ”€ Rule: "All dates in UTC ISO 8601. NO local times."
â”œâ”€ Validator: pd.to_datetime(df['game_date'], utc=True)
â”œâ”€ Rule: "All game dates normalized to Central Time (CST/CDT via America/Chicago) in ISO 8601. NO other local timezones."
â”œâ”€ Validator: pd.to_datetime(df['game_date']).dt.tz_localize('America/Chicago')
â”œâ”€ Why: Timezone inconsistencies cause time-based bugs. Central Time is the single canonical baseline.
â””â”€ Action: Convert all raw source timestamps to Central Time before storage
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Timezone inconsistencies cause time-based bugs.
â””â”€ Action: Convert to UTC before storage
```

### Barttorvik - 3 Guard Rails

```python
GuardRail #1: PRIOR SEASON RATINGS ONLY
â”œâ”€ Rule: "For season N games, use season N-1 ratings. NEVER same season."
â”œâ”€ Validator: assert df['ratings_season'] == df['game_season'] - 1
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Same-season ratings = information leakage from future data.
â””â”€ Documentation: Critical for valid backtests

GuardRail #2: RATING VALUE RANGES
â”œâ”€ Rule: "Efficiency: 50-150. Tempo: 60-80. Else = corruption."
â”œâ”€ Validator: assert df['adj_o'].between(50, 150).all()
â”œâ”€ Severity: WARNING
â”œâ”€ Why: Out-of-range values indicate API or parsing errors.
â””â”€ Action: Verify source data quality

GuardRail #3: TEAM COVERAGE BY SEASON
â”œâ”€ Rule: "95%+ of ~360 D1 teams must have ratings."
â”œâ”€ Validator: coverage = len(df) / 360; assert coverage >= 0.95
â”œâ”€ Severity: WARNING
â”œâ”€ Why: Low coverage indicates incomplete scrape.
â””â”€ Action: Verify Barttorvik has updated for the season
```

### NCAAR (ncaahoopR) - Planned Integration

```python
GuardRail #1: SCHEMA REQUIRED
â”œâ”€ Rule: "game_id, team, opp, points, home_away, date (all required)"
â”œâ”€ Validator: required = {'game_id', 'team', 'opp', 'points'}
â”œâ”€ Severity: ERROR

GuardRail #2: GAME MATCHING
â”œâ”€ Rule: "Each box score must match exactly ONE ESPN game"
â”œâ”€ Validator: unmatched = check_game_matching(ncaamr_df, espn_df)
â”œâ”€ Severity: ERROR

GuardRail #3: TEAM CONSISTENCY
â”œâ”€ Rule: "Team names must match ESPN canonical names exactly"
â”œâ”€ Validator: unresolved = ncaamr_df[~ncaamr_df['team'].isin(CANONICAL)]
â”œâ”€ Severity: ERROR
```

### Kaggle - 3 Guard Rails (When Activated)

```python
GuardRail #1: TOURNAMENT-ONLY SCOPE
â”œâ”€ Rule: "Kaggle has NCAA tournament ONLY (68 games March-April). NOT regular season."
â”œâ”€ Validator: dates = pd.to_datetime(df['date']); assert dates.dt.month.isin([3,4]).all()
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Confusing tournament with regular season causes data leakage.
â””â”€ Action: Use only for tournament predictions, not full-season model

GuardRail #2: NO ODDS WARNING
â”œâ”€ Rule: "Kaggle has no odds data. Cannot use alone for backtesting."
â”œâ”€ Validator: assert 'spread' not in df.columns or df['spread'].isnull().all()
â”œâ”€ Severity: WARNING
â”œâ”€ Why: Odds are critical for ROI backtesting.
â””â”€ Action: Merge with external odds before backtesting

GuardRail #3: TEAM RESOLUTION
â”œâ”€ Rule: "Kaggle team names must resolve to canonical names."
â”œâ”€ Validator: unresolved = df[~df['team'].isin(CANONICAL_TEAMS)]
â”œâ”€ Severity: ERROR
â”œâ”€ Why: Different naming conventions require explicit mapping.
â””â”€ Action: Document any new team name variants
```

---

## âœ… Part 3: QA/QC Implementation - Coverage Reports

Every data ingestion generates a **Coverage Report** showing:

### Coverage Matrix (Current State - January 12, 2026)

```
DATA SOURCE     | 2024 Season    | 2025 Season    | 2026 YTD
                | Games | % Odds | Games | % Odds | Games | % Odds
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
The Odds API    | 5,847 | 87.5% | 5,916 | 87.9% |   497 | 81.5%
ESPN Scores     | 5,847 | 100%  | 5,916 | 100%  |   520 | 99%
Barttorvik      | 5,847 | 80.2% | 5,916 | 79.5% |   497 | 65%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
H1 Scores       | 5,847 | 8.1%  | 5,916 | 7.9%  |   497 | 0%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NCAAR (inactive)| N/A            | N/A            | N/A
Kaggle (inactive)| 68 tournament only (no odds)
```

### QA/QC Rules by Data Type

#### ODDS Data QA/QC

```
âœ“ No Hardcoded Prices
  â””â”€ FAIL: Any spread_home_price = -110 (hardcoded)
  
âœ“ Sign Consistency  
  â””â”€ FAIL: Negative spread but home_price positive (mismatch)
  
âœ“ Price Ranges
  â””â”€ FAIL: Any price < -500 or > +500
  
âœ“ Game Uniqueness
  â””â”€ FAIL: Duplicate games by (game_id, home_team, away_team, market, game_date)
  
âœ“ Freshness (Current Season)
  â””â”€ FAIL: Data older than 48 hours (for 2026)
  
âœ“ Market Consistency
  â””â”€ WARN: If spread exists but total doesn't (should have both)
```

#### SCORES Data QA/QC

```
âœ“ Complete Pair
  â””â”€ FAIL: home_score without away_score (or vice versa)
  
âœ“ Reasonable Ranges
  â””â”€ WARN: Any score < 1 or > 200 for completed game
  
âœ“ Team Resolution
  â””â”€ FAIL: Any team name not in CANONICAL_TEAMS list
  
âœ“ Date Format
  â””â”€ FAIL: Any date not representing Central Time (CST/CDT, America/Chicago) in ISO 8601 form
  
âœ“ Unique Games
  â””â”€ FAIL: Duplicate games by (date, home_team, away_team)
  
âœ“ Score Finality
  â””â”€ WARN: Game marked as final but scores < 30 total (possible error)
```

#### RATINGS Data QA/QC

```
âœ“ Prior Season Only
  â””â”€ FAIL: ratings_season != game_season - 1
  
âœ“ Coverage Threshold
  â””â”€ WARN: < 90% of D1 teams have ratings for season
  
âœ“ Value Ranges
  â””â”€ WARN: Any rating < 50 or > 150 (adj_o, adj_d)
  
âœ“ Tempo Ranges
  â””â”€ WARN: Any tempo < 60 or > 80 (adj_t)
  
âœ“ Team Resolution
  â””â”€ FAIL: Any team not in CANONICAL_TEAMS
  
âœ“ Temporal Consistency
  â””â”€ WARN: If team's rating jumped >10 points in one update
```

---

## ğŸ”§ Part 4: Implementation - How to Activate

### Step 1: Run Data Governance Framework (DONE - Shows Status)

```bash
python testing/scripts/data_governance_framework.py
```

Output:
```
DATA GOVERNANCE FRAMEWORK - COMPREHENSIVE STATUS

ğŸ“Š DATA SOURCE INVENTORY:
  Active Sources:    3
  Inactive Sources:  2
  Planned Sources:   1
  Blocked Sources:   1

âœ… ACTIVE SOURCES (Currently Ingesting):
  â€¢ The Odds API (odds_api)
  â€¢ ESPN API (espn_api)
  â€¢ Barttorvik (barttorvik)

â¸ï¸  INACTIVE SOURCES (Available but NOT Ingested):
  â€¢ NCAAR (ncaamr)
  â€¢ Kaggle (kaggle)

ğŸ”® PLANNED SOURCES:
  â€¢ Basketball-API (basketball_api)

âœ… DATA GOVERNANCE FRAMEWORK READY FOR IMPLEMENTATION
```

### Step 2: Implement Guard Rail Validation (NEXT)

Create `testing/canonical/guard_rails_engine.py`:

```python
# Pseudo-code for guard rails validation
from data_governance_framework import REGISTRY, DataGovernanceValidator

# Create validator
validator = DataGovernanceValidator(
    strict_mode=True,  # BLOCK on errors
    audit_trail_path=Path("manifests/guard_rail_audit.json")
)

# When ingesting odds data:
result = validator.validate_data_source(
    df=odds_data,
    source_id="odds_api",
    data_type="odds",
    season=2026
)

if result["status"] == "FAIL":
    raise ValueError(f"Guard rail violations: {result['errors']}")
    # NOT SILENT FALLBACK - EXPLICIT ERROR

# When ingesting scores:
result = validator.validate_data_source(
    df=scores_data,
    source_id="espn_api",
    data_type="scores",
    season=2026
)

# Audit trail auto-saved
print(f"Audit trail: {validator.save_audit_trail()}")
```

### Step 3: Integrate Into Ingestion Pipeline

Modify `testing/scripts/fetch_historical_odds.py`:

```python
# BEFORE: No guard rails, silent fallbacks possible
def fetch_and_store(season):
    df = fetch_from_api(season)
    # Implicit assumptions, no validation
    write_to_azure(df)

# AFTER: Explicit validation, guard rails, audit trail
from testing.scripts.data_governance_framework import REGISTRY
from testing.canonical.guard_rails_engine import DataGovernanceValidator

def fetch_and_store(season):
    df = fetch_from_api(season)
    
    # 1. VALIDATE against guard rails (NO silent fallbacks)
    validator = DataGovernanceValidator(strict_mode=True)
    result = validator.validate_data_source(
        df=df,
        source_id="odds_api",
        data_type="odds",
        season=season
    )
    
    # 2. BLOCK if errors (not optional)
    if result["status"] == "FAIL":
        print(f"âŒ Guard rail violations:\n{result['errors']}")
        raise ValueError("Data failed validation. Check guard_rail_audit.json")
    
    # 3. LOG warnings (informational)
    if result["warnings"]:
        print(f"âš ï¸  Warnings (continuing):\n{result['warnings']}")
    
    # 4. STORE audit trail (immutable proof)
    validator.save_audit_trail()
    
    # 5. Finally, write to Azure
    write_to_azure(df)
    return True
```

### Step 4: Activate NCAAR Ingestion (Planned)

```python
# Create: testing/scripts/fetch_ncaahoopR_data.py

from testing.scripts.data_governance_framework import REGISTRY

# 1. Verify NCAAR source is ready
ncaamr_source = REGISTRY.find_by_id("ncaamr")
assert ncaamr_source.status == DataSourceStatus.INACTIVE  # Currently

# 2. Implement integration:
#    a. Load box scores from Azure ncaam-historical-raw
#    b. Validate against guard rails (game matching, team resolution)
#    c. Move to canonical_container (ncaam-historical-data)
#    d. Update ingestion_script and last_updated
#    e. Change status to ACTIVE

# 3. Update registry:
ncaamr_source.status = DataSourceStatus.ACTIVE
ncaamr_source.ingestion_script = "testing/scripts/fetch_ncaahoopR_data.py"
ncaamr_source.last_updated = datetime.now().isoformat()
```

### Step 5: Activate Kaggle Integration (Optional)

```python
# Create: testing/scripts/ingest_kaggle_data.py

# 1. Verify Kaggle data is in Azure
# 2. Guard rail #1: Check dates are tournament-only (March-April)
# 3. Merge with odds data via (date, home_team, away_team) join
# 4. Guard rail #2: Verify odds merged (not silent fallback to no-odds)
# 5. Guard rail #3: Verify team resolution
# 6. Store to canonical location
```

---

## ğŸ“Š Part 5: Audit Trail & Verification

Every data ingestion creates an **immutable audit trail**:

### Audit Trail Format (JSON)

```json
{
  "ingestion_id": "odds-api-2026-01-12-10-30-45",
  "timestamp": "2026-01-12T10:30:45Z",
  "source": "odds_api",
  "data_type": "odds",
  "season": 2026,
  "status": "PASS",
  "rows_ingested": 2156,
  "guard_rails_checked": 5,
  "guard_rails_passed": 5,
  "guard_rails_failed": 0,
  "errors": [],
  "warnings": [
    "odds_freshness: Some games older than 48 hours (historical data)"
  ],
  "validation_details": {
    "no_hardcoded_odds": "PASS",
    "spread_sign_convention": "PASS",
    "odds_price_ranges": "PASS",
    "no_duplicate_games": "PASS",
    "odds_freshness_by_season": "WARN"
  },
  "coverage": {
    "total_games_expected": 2200,
    "total_games_found": 2156,
    "coverage_pct": 98.0,
    "minimum_viable": 75.0,
    "status": "PASS"
  },
  "previous_audit": "odds-api-2026-01-11-10-30-45",
  "git_commit": "27cacd1",
  "azure_blob_path": "odds/normalized/odds_consolidated_canonical.csv"
}
```

### Check Audit Trail (Live)

```bash
# View latest ingestion audit
cat manifests/guard_rail_audit.json | tail -1 | jq '.'

# Check all NCAAR ingestions (once activated)
jq '.[] | select(.source=="ncaamr")' manifests/guard_rail_audit.json

# Verify odds are never hardcoded
jq '.[] | select(.source=="odds_api") | .validation_details.no_hardcoded_odds' manifests/guard_rail_audit.json

# Find any failed ingestions (should be none)
jq '.[] | select(.status=="FAIL")' manifests/guard_rail_audit.json
```

---

## ğŸ¯ Part 6: Single Source of Truth - Azure Storage

All data flows through this path (no local assumptions):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Sources    â”‚ (Odds API, ESPN, Barttorvik, NCAAR, Kaggle)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Guard Rails Validation             â”‚ â† Blocks bad data (NO fallbacks)
â”‚ - Schema checks                    â”‚
â”‚ - Range checks                     â”‚
â”‚ - Integrity checks                 â”‚
â”‚ - Consistency checks               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Team Resolution                   â”‚ â† Canonicalizes names
â”‚ (team_aliases_db.json â†’ canonical)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AZURE BLOB STORAGE (Single Source of Truth)    â”‚
â”‚ Container: ncaam-historical-data                â”‚
â”‚ â”œâ”€â”€ scores/fg/games_all.csv                     â”‚
â”‚ â”œâ”€â”€ scores/h1/h1_games_all.csv                  â”‚
â”‚ â”œâ”€â”€ odds/normalized/odds_consolidated.csv      â”‚
â”‚ â”œâ”€â”€ ratings/barttorvik/ratings_*.csv            â”‚
â”‚ â”œâ”€â”€ ncaahoopR_data-master/box_scores/...        â”‚
â”‚ â”œâ”€â”€ backtest_datasets/team_aliases_db.json      â”‚
â”‚ â””â”€â”€ manifests/guard_rail_audit.json â† AUDIT    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backtest Dataset Builder            â”‚
â”‚ (build_backtest_dataset_canonical)  â”‚
â”‚ - Joins scores + odds + ratings     â”‚
â”‚ - Validates coverage requirements   â”‚
â”‚ - Creates backtest_master.csv       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backtesting / Prediction            â”‚
â”‚ (run_historical_backtest.py)        â”‚
â”‚ (prediction-service-python)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Part 7: Checklist for Data Governance Compliance

Use this to verify EVERY data source meets standards:

### The Odds API Checklist

- [ ] Guard Rail #1: No hardcoded -110 odds
  - Verify: `df['spread_home_price'].value_counts()` has many values, not just -110
- [ ] Guard Rail #2: Spread sign convention consistent
  - Verify: If spread < 0, then home favored (check with moneyline direction)
- [ ] Guard Rail #3: Prices in [-500, +500]
  - Verify: `df['spread_home_price'].between(-500, 500).all()` = True
- [ ] Guard Rail #4: No duplicate games
  - Verify: `df.groupby(['game_id', 'market']).size().max()` = 1
- [ ] Guard Rail #5: Freshness by season
  - Verify: Current season data < 48 hours old
- [ ] Coverage: Expected for season
  - Verify: Coverage % matches `expected_coverage_pct` in registry

### ESPN API Checklist

- [ ] Guard Rail #1: Complete pairs
  - Verify: `(df['home_score'].isnull() == df['away_score'].isnull()).all()` = True
- [ ] Guard Rail #2: Reasonable ranges
  - Verify: `df['home_score'].between(1, 200).all()` = True
- [ ] Guard Rail #3: Team resolution
  - Verify: Zero unresolved teams (all in CANONICAL_TEAMS)
- [ ] Guard Rail #4: Date standardization
  - Verify: All dates represent Central Time (CST/CDT, America/Chicago) in ISO 8601 form
- [ ] Coverage: 95%+ of expected games
  - Verify: Coverage % â‰¥ `expected_coverage_pct` in registry

### Barttorvik Checklist

- [ ] Guard Rail #1: Prior season ratings only
  - Verify: `(df['ratings_season'] == df['game_season'] - 1).all()` = True
- [ ] Guard Rail #2: Value ranges
  - Verify: `df['adj_o'].between(50, 150).all()` = True
- [ ] Guard Rail #3: Team coverage
  - Verify: Coverage % â‰¥ `minimum_viable_coverage_pct` (90%)

### NCAAR (When Activated)

- [ ] Guard Rail #1: Schema present
- [ ] Guard Rail #2: Games match ESPN 1:1
- [ ] Guard Rail #3: Teams resolve
- [ ] Coverage: 95%+ of games have box scores
- [ ] Audit trail: All validations logged

### Kaggle (When Activated)

- [ ] Guard Rail #1: Dates are March-April only
- [ ] Guard Rail #2: No missing odds warning (addressed separately)
- [ ] Guard Rail #3: Teams resolve
- [ ] Coverage: 100% of 68 tournament games
- [ ] Scope: Clearly labeled as tournament-only

---

## ğŸš€ Next Steps (Priority Order)

### Immediate (This Week)

1. âœ… Run `data_governance_framework.py` to validate registry
2. âœ… Review guard rail definitions (above)
3. â¬œ Create `guard_rails_engine.py` with validation logic
4. â¬œ Integrate into `fetch_historical_odds.py` (test with 2026 data)
5. â¬œ Run audit and verify zero guard rail violations

### Short Term (Next 2 Weeks)

1. â¬œ Integrate guard rails into all fetch scripts
2. â¬œ Generate compliance report for all 3 active sources
3. â¬œ Archive `manifests/guard_rail_audit.json` weekly

### Medium Term (Q1 2026)

1. â¬œ Activate NCAAR ingestion through canonical pipeline
2. â¬œ Update registry status to ACTIVE
3. â¬œ Validate guard rails for NCAAR matches ESPN

### Long Term (Q2 2026)

1. â¬œ Activate Kaggle integration (tournament-only)
2. â¬œ Implement Basketball-API as secondary odds source
3. â¬œ Evaluate coverage with all 5 sources active

---

## ğŸ“ Questions & Answers

**Q: What happens if data fails a guard rail?**  
A: Ingestion BLOCKS with error. No silent fallbacks. You must:
1. Review audit trail to see which rule failed
2. Fix source data or adjust guard rail
3. Re-run ingestion

**Q: What if a source has data gaps?**  
A: Covered by coverage % validation. If below `minimum_viable_coverage_pct`, ingestion warns but continues (only if warnings allowed). If below required, ingestion blocks.

**Q: How do we know NCAAR data is correct when we activate it?**  
A: Guard rails #2 (game matching) validates each box score matches exactly one ESPN game. If any unmatched, ingestion fails.

**Q: What about Kaggle tournament games - how do we ensure they don't leak into regular season model?**  
A: Guard rail #1 enforces dates are March-April only. If tournament dates appear in regular season data, ingestion fails.

**Q: Can we make assumptions about missing data?**  
A: NO. Missing data must be explicitly handled:
- If odds are missing: Skip game or fill with explicit strategy (documented)
- If ratings are missing: Skip game or use league average (documented)
- If scores are missing: Skip game (never infer)

**Q: Who maintains the registry?**  
A: Data engineering team. Registry lives in `data_governance_framework.py`. Changes:
1. Update `REGISTRY.sources[]`
2. Re-run `data_governance_framework.py` to regenerate manifest
3. Commit to git
4. Update this documentation

---

## ğŸ“š Related Documents

- [SINGLE_SOURCE_OF_TRUTH.md](SINGLE_SOURCE_OF_TRUTH.md) - Azure storage structure
- [VALIDATION_GATES.md](VALIDATION_GATES.md) - Pre-prediction validation
- [DATA_SOURCES.md](DATA_SOURCES.md) - Current active sources
- [INGESTION_ARCHITECTURE.md](INGESTION_ARCHITECTURE.md) - Data flow diagram
- [manifests/data_sources_registry.json](../../manifests/data_sources_registry.json) - Machine-readable registry

---

**Version:** 1.0  
**Last Updated:** January 12, 2026  
**Status:** Implementation Ready  
**Next Review:** January 19, 2026
